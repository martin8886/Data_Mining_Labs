{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "XoyjX1GZph8e",
    "outputId": "c6afb4ca-a16f-42f8-a306-c87d11b72ee6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(71)\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import Callback\n",
    "from keras.utils import np_utils\n",
    "from keras.objectives import categorical_crossentropy\n",
    "from keras.datasets import cifar10, mnist\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import ArtistAnimation\n",
    "\n",
    "import multiprocessing as mp\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6UArRFHTo8Eo"
   },
   "outputs": [],
   "source": [
    "def Hbeta(D, beta):\n",
    "  P = np.exp(-D * beta)\n",
    "  sumP = np.sum(P) + 10e-15\n",
    "  \n",
    "  H = np.log(sumP) + beta * np.sum(D * P) / sumP\n",
    "  P = P / sumP\n",
    "  return H, P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GDNh5IcEo7Wz"
   },
   "outputs": [],
   "source": [
    "def x2p_job(data):\n",
    "    i, Di, tol, logU = data\n",
    "    beta = 1.0\n",
    "    betamin = -np.inf\n",
    "    betamax = np.inf\n",
    "    H, thisP = Hbeta(Di, beta)\n",
    "\n",
    "    Hdiff = H - logU\n",
    "    tries = 0\n",
    "    while np.abs(Hdiff) > tol and tries < 50:\n",
    "        if Hdiff > 0:\n",
    "            betamin = beta\n",
    "            if betamax == -np.inf:\n",
    "                beta = beta * 2\n",
    "            else:\n",
    "                beta = (betamin + betamax) / 2\n",
    "        else:\n",
    "            betamax = beta\n",
    "            if betamin == -np.inf:\n",
    "                beta = beta / 2\n",
    "            else:\n",
    "                beta = (betamin + betamax) / 2\n",
    "\n",
    "        H, thisP = Hbeta(Di, beta)\n",
    "        Hdiff = H - logU\n",
    "        tries += 1\n",
    "\n",
    "    return i, thisP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PR2q2Dbno6KZ"
   },
   "outputs": [],
   "source": [
    "def x2p(X):\n",
    "    tol = 1e-5\n",
    "    n = X.shape[0]\n",
    "    logU = np.log(perplexity)\n",
    "\n",
    "    sum_X = np.sum(np.square(X), axis=1)\n",
    "    D = sum_X + (sum_X.reshape([-1, 1]) - 2 * np.dot(X, X.T))\n",
    "\n",
    "    idx = (1 - np.eye(n)).astype(bool)\n",
    "    D = D[idx].reshape([n, -1])\n",
    "\n",
    "    def generator():\n",
    "        for i in range(n):\n",
    "            yield i, D[i], tol, logU\n",
    "\n",
    "    pool = mp.Pool(n_jobs)\n",
    "    result = pool.map(x2p_job, generator())\n",
    "    P = np.zeros([n, n])\n",
    "    for i, thisP in result:\n",
    "        P[i, idx[i]] = thisP\n",
    "\n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w-yYkr_Xo5Ht"
   },
   "outputs": [],
   "source": [
    "def calculate_P(X):\n",
    "    print (\"Computing pairwise distances...\")\n",
    "    n = X.shape[0]\n",
    "    P = np.zeros([n, batch_size])\n",
    "    for i in range(0, n, batch_size):\n",
    "        P_batch = x2p(X[i:i + batch_size])\n",
    "        P_batch[np.isnan(P_batch)] = 0\n",
    "        P_batch = P_batch + P_batch.T\n",
    "        P_batch = P_batch / P_batch.sum()\n",
    "        P_batch = np.maximum(P_batch, 1e-12)\n",
    "        P[i:i + batch_size] = P_batch\n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5n74kG8do4Rj"
   },
   "outputs": [],
   "source": [
    "def KLdivergence(P, Y):\n",
    "    low_dim = 2\n",
    "    alpha = low_dim - 1.\n",
    "    sum_Y = K.sum(K.square(Y), axis=1)\n",
    "    eps = K.variable(10e-15)\n",
    "    D = sum_Y + K.reshape(sum_Y, [-1, 1]) - 2 * K.dot(Y, K.transpose(Y))\n",
    "    Q = K.pow(1 + D / alpha, -(alpha + 1) / 2)\n",
    "    Q *= K.variable(1 - np.eye(batch_size))\n",
    "    Q /= K.sum(Q)\n",
    "    Q = K.maximum(Q, eps)\n",
    "    C = K.log(P) - K.log(Q)\n",
    "    C = K.sum(P * C)\n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eGufp78jgHnA"
   },
   "outputs": [],
   "source": [
    "def LoadData():\n",
    "  print (\"Loading cifar-10\")\n",
    "  (X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "  dataset = (X_train, y_train), (X_test, y_test)\n",
    "  return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I-j2uiu9ssfi"
   },
   "outputs": [],
   "source": [
    "def Reshape(dataset):\n",
    "  (X_train, y_train), (X_test, y_test) = dataset\n",
    "  n, channel, row, col = X_train.shape\n",
    "  X_train = X_train.reshape(-1, channel * row * col)\n",
    "  X_test = X_test.reshape(-1, channel * row * col)\n",
    "  \n",
    "  print (\"X_train.shape:\", X_train.shape)\n",
    "  print (\"X_test.shape:\", X_test.shape)\n",
    "\n",
    "  dataset = (X_train, y_train), (X_test, y_test), n\n",
    "  return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J3uwakE0kluc"
   },
   "outputs": [],
   "source": [
    "def Normalize(dataset):\n",
    "  (X_train, y_train), (X_test, y_test), n = dataset\n",
    "  print (\"Max in training data before scaling:\", str(np.max(X_train)))\n",
    "  \n",
    "  X_train = X_train.astype('float32')\n",
    "  X_test = X_test.astype('float32')\n",
    "  X_train /= 255\n",
    "  X_test /= 255\n",
    "  minimum = np.min(X_train)\n",
    "  maximum = np.max(y_train)\n",
    "  \n",
    "  print (\"Max in training data after scaling:\", str(np.max(X_train)))\n",
    "  \n",
    "  dataset = (X_train, y_train), (X_test, y_test), n\n",
    "  return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iRMniwLFhtUV"
   },
   "outputs": [],
   "source": [
    "def CompileModel(model, loss = KLdivergence, optimizer = \"adam\"):\n",
    "  model.compile(loss=loss, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M83j6cDXiMaa"
   },
   "outputs": [],
   "source": [
    "def FitModel():\n",
    "  (X_train, y_train), (X_test, y_test), n = dataset\n",
    "  \n",
    "  n_jobs = 4\n",
    "  batch_size = 1000\n",
    "  \n",
    "  low_dim = 2\n",
    "  nb_epoch = 50\n",
    "  shuffle_interval = nb_epoch + 1\n",
    "  \n",
    "  batch_num = int(n // batch_size)\n",
    "  m = batch_num * batch_size\n",
    "  \n",
    "  images = []\n",
    "  fig = plt.figure(figsize=(5, 5))\n",
    "\n",
    "  for epoch in range(nb_epoch):\n",
    "    # shuffle    \n",
    "    if epoch % shuffle_interval == 0:\n",
    "      X = X_train[np.random.permutation(n)[:m]]\n",
    "      P = calculate_P(X)\n",
    "\n",
    "    # train\n",
    "    loss = 0\n",
    "    for i in range(0, n, batch_size):\n",
    "        loss += model.train_on_batch(X[i:i+batch_size], P[i:i+batch_size])\n",
    "    \n",
    "    print (\"Epoch:\"+str(epoch+1)+\"/\"+str(nb_epoch)+\" loss: \"+str(loss/batch_num))\n",
    "\n",
    "    # visualize training\n",
    "    pred = model.predict(X_test)\n",
    "    img = plt.scatter(pred[:, 0], pred[:, 1], c=y_test, marker='o', s=3, edgecolor='')\n",
    "    images.append([img])\n",
    "    \n",
    "  # plot\n",
    "  plt.clf()\n",
    "  fig = plt.figure(figsize=(5, 5))\n",
    "  pred = model.predict(X_test)\n",
    "  plt.scatter(pred[:, 0], pred[:, 1], c=y_test, marker='o', s=4, edgecolor='')\n",
    "  fig.tight_layout()\n",
    "  plt.savefig(\"mlp_result.png\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U5pjZeXeth7f"
   },
   "outputs": [],
   "source": [
    "def GenerateBatch():\n",
    "    for i in range(0, n, batch_size):\n",
    "        P = calculate_P(X_train)\n",
    "        yield(X_train[i:i+batch_size], P[i:i+batch_size])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qLUSrvXysomd"
   },
   "outputs": [],
   "source": [
    "def AltFit():\n",
    "  (X_train, y_train), (X_test, y_test), n = dataset\n",
    "  \n",
    "  nb_epoch = 50\n",
    "    \n",
    "  history = model.fit_generator(GenerateBatch(),steps_per_epoch=math.ceil(n/batch_size), epochs=nb_epoch)\n",
    "  return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "AioWITpLhpVc",
    "outputId": "82edbeb7-90a9-46b1-c73b-6384620da8cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cifar-10\n",
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "123625472/170498071 [====================>.........] - ETA: 35s"
     ]
    }
   ],
   "source": [
    "dataset = Normalize(Reshape(LoadData()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "colab_type": "code",
    "id": "260yYvP0vHVj",
    "outputId": "0d73c43d-2eed-4e6b-9c30-e8e9e634ede3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0811 22:40:31.442429 139889707059072 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0811 22:40:32.634369 139889707059072 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0811 22:40:32.646214 139889707059072 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0811 22:40:32.719790 139889707059072 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0811 22:40:32.776007 139889707059072 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1521: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test), n = dataset\n",
    "X_train = X_train[0:10000]\n",
    "y_train = y_train[0:10000]\n",
    "\n",
    "perplexity = 30.0\n",
    "n_jobs = 4\n",
    "batch_size = 100\n",
    "\n",
    "nb_epoch = 50\n",
    "shuffle_interval = nb_epoch + 1\n",
    "\n",
    "batch_num = int(n // batch_size)\n",
    "m = batch_num * batch_size\n",
    "\n",
    "# build model\n",
    "model = Sequential()\n",
    "model.add(Dense(500, input_shape=(X_train.shape[1],)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(500))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(1000))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(2))\n",
    "model.compile(loss=KLdivergence, optimizer=\"adam\")\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QfEgjjQJxBUG"
   },
   "outputs": [],
   "source": [
    "# Plot the training and validation loss + accuracy\n",
    "def plot_training(history):\n",
    "    acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "    epochs = range(len(acc))\n",
    "\n",
    "    plt.plot(epochs, acc, 'r.')\n",
    "    plt.plot(epochs, val_acc, 'r')\n",
    "    plt.title('Training and validation accuracy')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    plt.savefig('acc_vs_epochs.png')\n",
    "\n",
    "# In[9]:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "colab_type": "code",
    "id": "6IYPfY5nv62c",
    "outputId": "a73ba746-5455-43ac-a670-05aed8b8cf82"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0811 22:40:32.898920 139889707059072 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0811 22:40:33.282837 139889707059072 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "Computing pairwise distances...\n",
      "Computing pairwise distances...\n",
      "  1/500 [..............................] - ETA: 2:42:37 - loss: 0.9468Computing pairwise distances...\n",
      "  2/500 [..............................] - ETA: 3:25:27 - loss: 0.8144Computing pairwise distances...\n"
     ]
    }
   ],
   "source": [
    "history = AltFit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HuOLSZY9x4zL"
   },
   "outputs": [],
   "source": [
    "\n",
    "plot_training(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2oQKtwubvRaF"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "CIFAR10 t-sne",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
