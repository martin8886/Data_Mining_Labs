{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab Two: Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will build upon the predictive analysis (classification) that we completed in the\n",
    "previous mini-project, adding additional modeling from new classification algorithms as well as\n",
    "more explanations that are inline with the CRISP-DM framework.\n",
    "\n",
    "We chose to continue to use the CIFAR-10 dataset. We identified the two tasks from the dataset to classify. \n",
    "Task 1: Cats and dogs\n",
    "Task 2: Birds and airplanes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By Martin Garcia, Joanna Duran, Daniel Byrne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "import sklearn.naive_bayes as b\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.ndimage import convolve\n",
    "\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.utils import compute_class_weight\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (5.0, 4.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Minilab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Understanding\n",
    "Our objective was to create a logistic regression model and a support vector machine model for the classification of each image. We were to determine which model is best suited for this standard classification task based on a comparison on their prediction accuracy, training times, and computational efficiency.\n",
    "\n",
    "The CIFAR-10 dataset (Canadian Institute For Advanced Research) is a collection of images that are commonly used to train machine learning and computer vision algorithms. It is one of the most widely used datasets for machine learning research. It is a subset of the 80 million tiny images dataset and consists of 60,000 32x32 color images containing one of 10 object classes, with 6,000 images per class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Meaning Type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The CIFAR-10 dataset\n",
    "We are using the [CIFAR-10](http://www.cs.toronto.edu/~kriz/cifar.html) dataset which consists of 60,000 32x32 colour images in 10 classes, with 6,000 images per class. The dataset includes are 50,000(80%) training images and 10,000(20%) test images broken in to 5 pre-randomized training batches and 1 test batch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each training batch contains 10,000 observations with a row vector of length 3,072 representative of color image of 32x32 pixels. The first 1,024 columns consist of red values, followed by green, and blue. The data also incorporates labels ranging from 0 to 9 and are listed below.\n",
    "\n",
    "* airplane : 0\n",
    "* automobile : 1\n",
    "* bird : 2\n",
    "* cat : 3\n",
    "* deer : 4\n",
    "* dog : 5\n",
    "* frog : 6\n",
    "* horse : 7\n",
    "* ship : 8\n",
    "* truck : 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test batch contains 1,000 randomly-selected images from each class. The 5 training batches are randomized and contain a variable number of images from each class. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classes are completely mutually exclusive. There is no overlap between automobiles and trucks. \"Automobile\" includes sedans, SUVs, things of that sort. \"Truck\" includes only big trucks. Neither includes pickup trucks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data, reshape to 32x32 matrix per color, transpose matrices\n",
    "def load_cfar10_batch(path, batch_id = None, reshape = True):\n",
    "    \"\"\"\n",
    "    Argument:\n",
    "    path -- path the datasets\n",
    "    batch_id -- id of the batch (1 to 5) to load\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- python dictionary containing:\n",
    "                    X -- features\n",
    "                    Y -- labels\n",
    "    \"\"\"\n",
    "    if batch_id is not None:\n",
    "        filepath = path + 'data_batch_' + str(batch_id)\n",
    "    else:\n",
    "        filepath = path\n",
    "        \n",
    "    with open(filepath, mode='rb') as file:\n",
    "        # note the encoding type is 'latin1'\n",
    "        batch = pickle.load(file, encoding='latin1')\n",
    "    \n",
    "    if reshape:    \n",
    "        X = batch['data'].reshape((len(batch['data']), 3, 32, 32)).transpose(0, 2, 3, 1)\n",
    "        Y = np.array(batch['labels'])\n",
    "    else:\n",
    "        X = batch['data']\n",
    "        Y = np.array(batch['labels'])\n",
    "        \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cfar10_dataset():\n",
    "    \"\"\"\n",
    "    Loads the cfar10 dataset\n",
    "    \n",
    "    Arguments: \n",
    "        None\n",
    "    \n",
    "    Returns:\n",
    "        X - Training dataset\n",
    "        Y - Training labels\n",
    "         - Test datset\n",
    "        y_test - test labelss\n",
    "    \"\"\"\n",
    "    x_test,y_test = load_cfar10_batch(\"data/test_batch\",None,False)\n",
    "    X,Y = load_cfar10_batch(\"data/\",1,False)\n",
    "\n",
    "    for n in range(2,6):\n",
    "        x,y = load_cfar10_batch(\"data/\",n,False)    \n",
    "        X = np.concatenate((X,x),axis=0)\n",
    "        Y = np.concatenate((Y,y),axis=0)\n",
    "\n",
    "\n",
    "    return (X,Y,x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load labels for our label\n",
    "def load_label_names():\n",
    "    return ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "#display images\n",
    "def display_stats(data, batch_id, sample_id):\n",
    "    features, labels = load_cfar10_batch(data, batch_id)\n",
    "\n",
    "    if not (0 <= sample_id < len(features)):\n",
    "        print('{} samples in batch {}.  {} is out of range.'.format(len(features), batch_id, sample_id))\n",
    "        return None\n",
    "\n",
    "    print('\\nStats of batch #{}:'.format(batch_id))\n",
    "    print('# of Samples: {}\\n'.format(len(features)))\n",
    "\n",
    "    label_names = load_label_names()\n",
    "    label_counts = dict(zip(*np.unique(labels, return_counts=True)))\n",
    "    for key, value in label_counts.items():\n",
    "        print('Label Counts of [{}]({}) : {}'.format(key, label_names[key].upper(), value))\n",
    "\n",
    "    sample_image = features[sample_id]\n",
    "    sample_label = labels[sample_id]\n",
    "\n",
    "    print('\\nExample of Image {}:'.format(sample_id))\n",
    "    print('Image - Min Value: {} Max Value: {}'.format(sample_image.min(), sample_image.max()))\n",
    "    print('Image - Shape: {}'.format(sample_image.shape))\n",
    "    print('Label - Label Id: {} Name: {}'.format(sample_label, label_names[sample_label]))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(sample_image)\n",
    "\n",
    "batch_id = random.randint(1,5)\n",
    "sample_id = random.randint(1,10000)\n",
    "display_stats( \"data/\", batch_id, sample_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will define and prepare our class variables. \n",
    "\n",
    "Each of the batch files contains a dictionary with the following elements: \n",
    "\n",
    "data -- a 10000x3072 numpy array of uint8s. Each row of the array stores a 32x32 colour image. The first 1024 entries contain the red channel values, the next 1024 the green, and the final 1024 the blue. The image is stored in row-major order, so that the first 32 entries of the array are the red channel values of the first row of the image. \n",
    "\n",
    "labels -- a list of 10000 numbers in the range 0-9. The number at index i indicates the label of the ith image in the array data.\n",
    "\n",
    "The dataset contains another file, called batches.meta. It too contains a Python dictionary object. It has the following entries: \n",
    "\n",
    "label_names -- a 10-element list which gives meaningful names to the numeric labels in the labels array described above. For example, label_names[0] == \"airplane\", label_names[1] == \"automobile\", etc.\n",
    "\n",
    "\"Define and prepare your class variables. Use proper variable representations (int, float, one-hot, etc.). Use pre-processing methods (as needed) for dimensionality reduction, scaling, etc. Remove variables that are not needed/useful for the analysis.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplify_labels(df,indexes,val = 10):\n",
    "    \"\"\"\n",
    "    Return a modified label dataset filtered ot use only the classes specified\n",
    "\n",
    "    Arguments:\n",
    "    indees: indexes to filter\n",
    "    df : label dataset\n",
    "    val: new label value\n",
    "\n",
    "    Returns:\n",
    "    fdf - filtered df\n",
    "      \n",
    "    \"\"\"\n",
    "\n",
    "    def f(n):\n",
    "        if n in indexes:\n",
    "            return n\n",
    "        else:\n",
    "            return val\n",
    "    \n",
    "    return np.array(list(map(f,df)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nudge_dataset(X, Y):\n",
    "    \"\"\"\n",
    "    This produces a dataset 5 times bigger than the original one,\n",
    "    by moving the 32x32 images in X around by 1px to left, right, down, up.\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    direction_vectors = np.array([\n",
    "        [[[0, 1, 0],\n",
    "          [0, 0, 0],\n",
    "          [0, 0, 0]]],\n",
    "\n",
    "        [[[0, 0, 0],\n",
    "          [1, 0, 0],\n",
    "          [0, 0, 0]]],\n",
    "\n",
    "        [[[0, 0, 0],\n",
    "         [0, 0, 1],\n",
    "         [0, 0, 0]]],\n",
    "\n",
    "        [[[0, 0, 0],\n",
    "         [0, 0, 0],\n",
    "         [0, 1, 0]]]\n",
    "    ])\n",
    "    \n",
    "    def shift(x, w):\n",
    "        c = convolve(x.reshape((3,32,32)), mode='constant', weights=w).ravel()\n",
    "        return c\n",
    "\n",
    "    X = np.concatenate([X] +\n",
    "                       [np.apply_along_axis(shift, 1, X, vector)\n",
    "                        for vector in direction_vectors])\n",
    "    Y = np.concatenate([Y for _ in range(5)], axis=0)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data\n",
    "X,Y,x_test,y_test = load_cfar10_dataset()\n",
    "\n",
    "\n",
    "# In order to learn good latent representations from a small dataset, \n",
    "# we artificially generate more labeled data by perturbing the training\n",
    "# data with linear shifts of 1 pixel in each direction.\n",
    "X, Y = nudge_dataset(X, Y)\n",
    "x_test, y_test = nudge_dataset(x_test, y_test)\n",
    "\n",
    "# Simplify label datasets to only the classes we care about\n",
    "Ycatdog = simplify_labels(Y,[3,5],10)\n",
    "y_test_catdog =simplify_labels(y_test,[3,5],10)\n",
    "Ybirdplane = simplify_labels(Y,[0,2],10)\n",
    "y_test_birdplane = simplify_labels(y_test,[0,2],10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Reduction\n",
    "\n",
    "The final training dataset is identical to the original.  However, we've created 4 new label datasets targeting the labels we want our models to classify\n",
    "\n",
    "- Ycatdog, y_test_catdog  : Cat and dog labels are retained, all others forced to next unused label\n",
    "- Ybirdplane,y_test_birdplane : Bird and plane  labels are retained, all others forced to next unused label\n",
    "\n",
    "### Artificial Data Augmentation\n",
    "\n",
    "In order to learn good latent representations from a small dataset, \n",
    "we artificially generate more labeled data by perturbing the training\n",
    "data with linear shifts of 1 pixel in each direction.\n",
    "\n",
    "Other augmentations such as color shifting, rotation and cropping are useful and often used as well in preparing image data for deeplearning tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plti(im, h=2, **kwargs):\n",
    "    \"\"\"\n",
    "    Helper function to plot an image.\n",
    "    \"\"\"\n",
    "    y = im.shape[0]\n",
    "    x = im.shape[1]\n",
    "    w = (y/x) * h\n",
    "    plt.figure(figsize=(w,h))\n",
    "    plt.imshow(im, interpolation=\"none\", **kwargs)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot augmented images\n",
    "\n",
    "plti(X[0].reshape((3,32,32)).transpose(1,2,0))\n",
    "plti(X[50000].reshape((3,32,32)).transpose(1,2,0))\n",
    "plti(X[100000].reshape((3,32,32)).transpose(1,2,0))\n",
    "plti(X[150000].reshape((3,32,32)).transpose(1,2,0))\n",
    "plti(X[200000].reshape((3,32,32)).transpose(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Augmented Data shape: \",X.shape)\n",
    "print(\"Augmented Labels shape: \",Ycatdog.shape)\n",
    "\n",
    "print(\"Augmented Test Data shape: \",x_test.shape)\n",
    "print(\"Augmented Test Labels shape: \",y_test_catdog.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Scaling\n",
    "\n",
    "Multi-layer Perceptrons are sensitive to feature scaling, so sklearn highly recommendeds scaling the data.  The same scaling must be applied to the test set for meaningful results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data Scaling\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "scaler = StandardScaler()  \n",
    "scaler.fit(X)  \n",
    "Xmlp = scaler.transform(X)  \n",
    "x_testmlp = scaler.transform(x_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling and Evaluation 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using machine learning to detect and classify images is becoming a very common occurrence. It is being used for the detection of oil spills in satellite radar images as well as gender classification on real-world face images. \n",
    "\n",
    "For our project we will classify images into 10 classes. Since this is a large number of classes, overall accuracy is a definite concern. We want to ensure that the number of false positives are low. Another factor that influences the number of false positives/ negatives is if the classes are not balanced. For our data set this is not a concern because our ten classes each have the same number of samples.\n",
    "\n",
    "\"Choose and explain your evaluation metrics that you will use (i.e., accuracy,\n",
    "precision, recall, F-measure, or any metric we have discussed). Why are the measure(s) appropriate for analyzing the results of your modeling? Give a detailed explanation backing up any assertions.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling and Evaluation 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We will assess how well each model performs (use 80/20 training/testing split)and adjust parameters of the models to make them more accurate. \n",
    "\n",
    "\n",
    "\"Choose the method you will use for dividing your data into training and\n",
    "testing splits (i.e., are you using Stratified 10-fold cross validation? Why?). Explain why\n",
    "your chosen method is appropriate or use more than one method as appropriate. For example, if you are using time series data then you should be using continuous training and testing sets across time.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling and Evaluation 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We identified the two tasks from the dataset to classify. For each task we will create three different classification/regression models\n",
    "\n",
    "Task 1: Cats and dogs\n",
    "\n",
    "    Model A: Naive Bayes\n",
    "    Model B: Multi-layer Perceptron classifier (MLP)\n",
    "    Model C: Support Vector Machine (SVM)\n",
    "    \n",
    "Task 2: Birds and airplanes\n",
    "\n",
    "    Model A: Naive Bayes\n",
    "    Model B: Decision Tree\n",
    "    Model C: SVM\n",
    "\n",
    "\"Create three different classiﬁcation/regression models (e.g., random forest, KNN, and SVM). Two modeling techniques must be new (but the third could be SVM or logistic regression). Adjust parameters as appropriate to increase generalization performance using your chosen metric\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1 Model A\n",
    "Cats and Dogs- Naive Bayes, Multi-layer Perceptron classifier and Support Vector Machine\n",
    "    \n",
    "We chose several implementations of the Naive Bayes classifier: GaussianNB, MultinomialNB, and BernoulliNB.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildmodel(nmodel,X,Y,x_test,y_test,**modelargs):\n",
    "    \"\"\"\n",
    "    Builds one of a subset of sklearn models and returns a score\n",
    "    \n",
    "    Arguments:\n",
    "    modeltype -- One of either \"multi\", \"gauss\", \"bernoulli\", \"c\", \"nn\" \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    if nmodel == 'multi':\n",
    "        m = b.MultinomialNB(**modelargs)\n",
    "    elif nmodel == 'gauss':\n",
    "        m = b.GaussianNB(**modelargs)\n",
    "    elif nmodel == 'bernoulli':\n",
    "        m = b.BernoulliNB(**modelargs)\n",
    "    elif nmodel == \"mlp\":\n",
    "        m = MLPClassifier(**modelargs)\n",
    "    elif nmodel == \"svm\":\n",
    "        m = SGDClassifier(**modelargs)\n",
    "    elif nmodel == \"BernoulliRBM\":\n",
    "        m = BernoulliRBM(**modelargs)\n",
    "    elif nmodel == \"LogisticRegression\":\n",
    "        m = LogisticRegression(**modelargs)\n",
    "    \n",
    "    m.fit(X, Y)\n",
    "    score = m.score(x_test,y_test) * 100\n",
    "\n",
    "    return m,score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "berboulliNB, bernoulliNBScore = buildmodel('bernoulli',X,Ycatdog,x_test,y_test_catdog,alpha = .01)\n",
    "print(\"BernoulliNB score :%\",round(bernoulliNBScore,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp, mlpScore = buildmodel('mlp',Xmlp,Ycatdog,x_testmlp,y_test_catdog,\n",
    "                           activation = 'relu',hidden_layer_sizes=(10,),learning_rate ='adaptive',verbose = True, tol = .001,\n",
    "                           max_iter = 50, n_iter_no_change =5)\n",
    "print(\"Multi-layer Perceptron score :%\",round(mlpScore,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm, svmScore = buildmodel('bernoulli',X,Ycatdog,x_test,y_test_catdog,alpha=0.001, max_iter=500, \n",
    "                           tol=.01,verbose=1,n_jobs=4,loss=\"log\",n_iter_no_change =5)\n",
    "print(\"BernoulliNB score :%\",round(svmScore,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the Naive Bayes model, while MultinomialNB and GaussianNB scores were relatively similar(54.28% and 54.31%, respectively), BernoulliNB  was higher at 77.17%.  \n",
    "The Multi-layer Perceptron classifier resulted in 80% which surpasses Naive Bayes.\n",
    "The Support Vector Machine returned a 79.7%.\n",
    "Being that BernoulliNB, Multi-layer Perceptron classifier and Support Vector Machine are all very similar in score, other factors will be taken into consideration when finding the optimal model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task2 Model A\n",
    "(Birds and Airplanes- Naive Bayes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task2 Model B\n",
    "(Birds and Airplanes- Decision Tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task2 Model C\n",
    "(Birds and Airplanes- SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling and Evaluation 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Analyze the results using your chosen method of evaluation. Use visualizations of the results to bolster the analysis. Explain any visuals and analyze why they are interesting to someone that might use this model.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling and Evaluation 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Advantages of Task 1: Cats and dogs Model A: Naive Bayes\n",
    "\n",
    "    *\n",
    "Advantages of Task 1: Cats and dogsModel B: Multi-layer Perceptron classifier (MLP)\n",
    "\n",
    "    *\n",
    "Advantages of Task 1: Cats and dogsModel C: Support Vector Machine (SVM)\n",
    "\n",
    "    *\n",
    "Advantages of Task 2: Birds and airplanes Model A: Naive Bayes\n",
    "\n",
    "    *\n",
    "Advantages of Task 2: Birds and airplanes Model B: Decision Tree\n",
    "\n",
    "    *\n",
    "Advantages of Task 2: Birds and airplanes Model C: SVM\n",
    "\n",
    "    *\n",
    "\n",
    "\"Discuss the advantages of each model for each classification task, if any. If there are not advantages, explain why. Is any model better than another? Is the difference significant with 95% confidence? Use proper statistical comparison methods. You must use statistical comparison techniques—be sure they are appropriate for your chosen method of validation as discussed in unit 7 of the course.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling and Evaluation 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Which attributes from your analysis are most important? Use proper methods discussed in class to evaluate the importance of different attributes. Discuss the results and hypothesize about why certain attributes are more important than others for a given classiﬁcation task. Attributes are pixels representing a range of values 0-255 for each pixel. Together they represent a coefficients or loadings that together build an image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Range of values in our elements\n",
    "np.min(X),np.max(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We scale the data due to large ranges in values from 0-255\n",
    "scaler = StandardScaler()\n",
    "# Fit on training set only.\n",
    "scaler.fit(X)\n",
    "# Apply transform to both the training set\n",
    "X_trans = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new scaled range\n",
    "np.min(X_trans),np.max(X_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We add attribute names to each of our columns\n",
    "feat_cols = ['pixel '+str(i) for i in range(X_trans.shape[1])]\n",
    "#Create dataframe for our scaled elements and incorporate column names\n",
    "df_cifar = pd.DataFrame(X_trans,columns=feat_cols)\n",
    "df_cifar['label'] = Y\n",
    "#preview \n",
    "df_cifar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#break into two new components, prin1 and prin2\n",
    "pca_cifar = PCA(n_components=2)\n",
    "principalComponents_cifar = pca_cifar.fit_transform(X_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-d7eab5fc5a19>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m principal_cifar_Df = pd.DataFrame(data = principalComponents_cifar\n\u001b[0m\u001b[0;32m      2\u001b[0m              , columns = ['prin 1', 'prin 2'])\n\u001b[0;32m      3\u001b[0m \u001b[0mprincipal_cifar_Df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'y'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "#add labels\n",
    "principal_cifar_Df = pd.DataFrame(data = principalComponents_cifar\n",
    "             , columns = ['prin 1', 'prin 2'])\n",
    "principal_cifar_Df['y'] = Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#percentage of variance explained\n",
    "print('Explained variation per principal component: {}'.format(pca_cifar.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "principal_cifar_Df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We believe that our model would be best suited for\n",
    "\n",
    "\"How useful is your model for interested parties (i.e., the companies or organizations that might want to use it for prediction)? How would you measure the model's value if it was used by these parties? How would your deploy your model for interested parties? What other data should be collected? How often would the model need to be updated, etc.?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OLD- MAY DELETE -Create Models\n",
    "\n",
    "In this section we will create a logistic regression model and a support vector machine model for the classification task involved with your dataset.  We will assess how well each model performs (use 80/20 training/testing split)and adjust parameters of the models to make them more accurate. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of our primary concerns was that single level logistic regression cannot handle a multiclass problem very well.  In order to tackle this issue we decided to change to simplify the problem to a binary classification exercise. We modified the training labels to be either the \"CAT\"/\"NOT CAT\" which simplified the task for our models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OLD- MAY DELETE -Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Build Logistic Regression Model with Stochastic Gradient Descent \n",
    "X,Y = load_cfar10_batch(\"data/\",1,False)\n",
    "\n",
    "for n in range(2,6):\n",
    "    x,y = load_cfar10_batch(\"data/\",n,False)    \n",
    "    X = np.concatenate((X,x),axis=0)\n",
    "    Y = np.concatenate((Y,y),axis=0)\n",
    "\n",
    "test_X,test_Y = load_cfar10_batch(\"data/test_batch\",None,False)\n",
    "\n",
    "# Modify the dataset labels to lable cats/not/cats\n",
    "#(if_test_is_false, if_test_is_true)[test]\n",
    "catY = (Y == 3)\n",
    "cat_test_Y = (test_Y == 3) \n",
    "\n",
    "sgdlr = SGDClassifier(alpha=0.001, max_iter=5000, tol=1e-3,verbose=1,n_jobs=4,loss=\"log\")\n",
    "\n",
    "print(\"Data shape: \",X.shape)\n",
    "print(\"Labels shape: \",catY.shape)\n",
    "\n",
    "print(\"Test Data shape: \",test_X.shape)\n",
    "print(\"Test Labels shape: \",cat_test_Y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "sgdlr.fit(X,catY)\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print(\"Training complete.  Time elapsed = \",elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgdlrscore = sgdlr.score(test_X,cat_test_Y)\n",
    "print(\"Logistic Regression Accuracy: \",sgdlrscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OLD- MAY DELETE -Model Comparison\n",
    "\n",
    "The two models were trained with similar hyperparameters to simplify the A/B comparison between the two models.  The only parameter that varied between the two models was the *loss* parameter. \n",
    "\n",
    "The loss function defaults to ‘hinge’, which gives a linear SVM. The ‘log’ loss gives logistic regression, a probabilistic classifier. \n",
    "\n",
    "The two models we cerated in identifying cats peformed similarly in terms of accuracy, 85% to 89% accuaracy over several test runs.\n",
    "\n",
    "Training times varied depending on the underlying hardware and computer workload; however, the two models were comparable in overall training times on this dataset 69-72 seconds on Intel Core i7-6700 @ 3.4GHz, 24Gb of RAM, 4 Cores, and and NVIDIA 1060. \n",
    "\n",
    "Both models also seemed to mislabel similar images as evident in the plots above.  Both models seemed to struggle with cats in odd, off center poses, or curled up into a ball.  The one car image that was mislabaled as a cat kind of resemebles a cat with the openned hatchback of the car resembling a tail.\n",
    "\n",
    "Overall both models performed similarily in this classification task with the chosen model parameters."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
