{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minilab "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Martin Garcia, Joanna Duran, Daniel Byrne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required Packages\n",
    "* numpy\n",
    "* pandas\n",
    "* pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CIFAR-10 dataset (Canadian Institute For Advanced Research) is a collection of images that are commonly used to train machine learning and computer vision algorithms. It is one of the most widely used datasets for machine learning research. It is a subset of the 80 million tiny images dataset and consists of 60,000 32x32 color images containing one of 10 object classes, with 6,000 images per class. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our objective is to create a logistic regression model and a support vector machine model for the classification of each image. We will determine which is a better model based on  prediction accuracy and training time and efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Meaning Type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is broken down into six batches; five training and one test batches. Each training batch consist of 10,000 observations with a row vector of length 3072 representative of color image of 32x32 pixels. The first 1024 columns consist of red values, followed by green, and blue. The data also incorporates labels ranging from 0 to 9 and are listed below.\n",
    "\n",
    "* airplane : 0\n",
    "* automobile : 1\n",
    "* bird : 2\n",
    "* cat : 3\n",
    "* deer : 4\n",
    "* dog : 5\n",
    "* frog : 6\n",
    "* horse : 7\n",
    "* ship : 8\n",
    "* truck : 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test batch contains exactly 1,000 randomly-selected images from each class. The training batches contain the remaining images in random order, but some training batches may contain more images from one class than another. Between them, the training batches contain exactly 5000 images from each class. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classes are completely mutually exclusive. There is no overlap between automobiles and trucks. \"Automobile\" includes sedans, SUVs, things of that sort. \"Truck\" includes only big trucks. Neither includes pickup trucks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch #3:\n",
      "# of Samples: 10000\n",
      "\n",
      "Label Counts of [0](AIRPLANE) : 994\n",
      "Label Counts of [1](AUTOMOBILE) : 1042\n",
      "Label Counts of [2](BIRD) : 965\n",
      "Label Counts of [3](CAT) : 997\n",
      "Label Counts of [4](DEER) : 990\n",
      "Label Counts of [5](DOG) : 1029\n",
      "Label Counts of [6](FROG) : 978\n",
      "Label Counts of [7](HORSE) : 1015\n",
      "Label Counts of [8](SHIP) : 961\n",
      "Label Counts of [9](TRUCK) : 1029\n",
      "\n",
      "Example of Image 7000:\n",
      "Image - Min Value: 24 Max Value: 252\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 0 Name: airplane\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#load the data, reshape to 32x32 matrix per color, transpose matrices\n",
    "def load_cfar10_batch(data, batch_id):\n",
    "    with open(data + '/data_batch_' + str(batch_id), mode='rb') as file:\n",
    "        # note the encoding type is 'latin1'\n",
    "        batch = pickle.load(file, encoding='latin1')\n",
    "        \n",
    "    features = batch['data'].reshape((len(batch['data']), 3, 32, 32)).transpose(0, 2, 3, 1)\n",
    "    labels = batch['labels']\n",
    "        \n",
    "    return features, labels\n",
    "\n",
    "#load labels for our label\n",
    "def load_label_names():\n",
    "    return ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "#display images\n",
    "def display_stats(data, batch_id, sample_id):\n",
    "    features, labels = load_cfar10_batch(data, batch_id)\n",
    "\n",
    "    if not (0 <= sample_id < len(features)):\n",
    "        print('{} samples in batch {}.  {} is out of range.'.format(len(features), batch_id, sample_id))\n",
    "        return None\n",
    "\n",
    "    print('\\nStats of batch #{}:'.format(batch_id))\n",
    "    print('# of Samples: {}\\n'.format(len(features)))\n",
    "\n",
    "    label_names = load_label_names()\n",
    "    label_counts = dict(zip(*np.unique(labels, return_counts=True)))\n",
    "    for key, value in label_counts.items():\n",
    "        print('Label Counts of [{}]({}) : {}'.format(key, label_names[key].upper(), value))\n",
    "\n",
    "    sample_image = features[sample_id]\n",
    "    sample_label = labels[sample_id]\n",
    "\n",
    "    print('\\nExample of Image {}:'.format(sample_id))\n",
    "    print('Image - Min Value: {} Max Value: {}'.format(sample_image.min(), sample_image.max()))\n",
    "    print('Image - Shape: {}'.format(sample_image.shape))\n",
    "    print('Label - Label Id: {} Name: {}'.format(sample_label, label_names[sample_label]))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(sample_image)\n",
    "\n",
    "batch_id = 3\n",
    "sample_id = 7000\n",
    "display_stats( \"data/\", batch_id, sample_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Models\n",
    "\n",
    "In this section we will create a logistic regression model and a support vector machine model for the classification task involved with your dataset.  We will assess how well each model performs (use 80/20 training/testing split)and adjust parameters of the models to make them more accurate. \n",
    "\n",
    "*If your dataset size requires the use of stochastic gradient descent, then linear kernel only is fine to use. That is, the SGDClassifier is fine to use for optimizing logistic regression and linear support vector machines. For many problems, SGD will be required in order to train the SVM model in a reasonable timeframe. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression Model\n",
    "\n",
    "* advantages\n",
    "* weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Machine Model\n",
    "\n",
    "* advantages\n",
    "* classification task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Advantages\n",
    "\n",
    "In this section we will discuss the advantages of each model for each classification task. Does one type of model offer superior performance over another in terms of prediction accuracy? In terms of training time or efficiency? Explain in detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting Feature Importance\n",
    "\n",
    "In this section we will use the weights from logistic regression to interpret the importance of different features for the classification task. Explain your interpretation in detail. Why do you think some variables are more important?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting Support Vectors\n",
    "\n",
    "In this section we will look at the chosen support vectors for the classification task. Do these provide any insight into the data? Explain. If you used stochastic gradient descent (and therefore did not explicitly solve for support vectors), try subsampling your data to train the SVC model— then analyze the support vectors from the subsampled dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
