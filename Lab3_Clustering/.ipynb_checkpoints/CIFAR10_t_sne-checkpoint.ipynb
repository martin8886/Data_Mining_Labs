{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "XoyjX1GZph8e",
    "outputId": "15f059bc-85b9-407c-e468-eaef3b3d41d4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(71)\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import cifar10\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import multiprocessing as mp\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6UArRFHTo8Eo"
   },
   "outputs": [],
   "source": [
    "def Hbeta(D, beta):\n",
    "  P = np.exp(-D * beta)\n",
    "  sumP = np.sum(P) + 10e-15\n",
    "  \n",
    "  H = np.log(sumP) + beta * np.sum(D * P) / sumP\n",
    "  P = P / sumP\n",
    "  return H, P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GDNh5IcEo7Wz"
   },
   "outputs": [],
   "source": [
    "def x2p_job(data):\n",
    "    i, Di, tol, logU = data\n",
    "    beta = 1.0\n",
    "    betamin = -np.inf\n",
    "    betamax = np.inf\n",
    "    H, thisP = Hbeta(Di, beta)\n",
    "\n",
    "    Hdiff = H - logU\n",
    "    tries = 0\n",
    "    while np.abs(Hdiff) > tol and tries < 50:\n",
    "        if Hdiff > 0:\n",
    "            betamin = beta\n",
    "            if betamax == -np.inf:\n",
    "                beta = beta * 2\n",
    "            else:\n",
    "                beta = (betamin + betamax) / 2\n",
    "        else:\n",
    "            betamax = beta\n",
    "            if betamin == -np.inf:\n",
    "                beta = beta / 2\n",
    "            else:\n",
    "                beta = (betamin + betamax) / 2\n",
    "\n",
    "        H, thisP = Hbeta(Di, beta)\n",
    "        Hdiff = H - logU\n",
    "        tries += 1\n",
    "\n",
    "    return i, thisP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PR2q2Dbno6KZ"
   },
   "outputs": [],
   "source": [
    "def x2p(X):\n",
    "    tol = 1e-5\n",
    "    n = X.shape[0]\n",
    "    logU = np.log(perplexity)\n",
    "\n",
    "    sum_X = np.sum(np.square(X), axis=1)\n",
    "    D = sum_X + (sum_X.reshape([-1, 1]) - 2 * np.dot(X, X.T))\n",
    "\n",
    "    idx = (1 - np.eye(n)).astype(bool)\n",
    "    D = D[idx].reshape([n, -1])\n",
    "\n",
    "    def generator():\n",
    "        for i in range(n):\n",
    "            yield i, D[i], tol, logU\n",
    "\n",
    "    pool = mp.Pool(n_jobs)\n",
    "    result = pool.map(x2p_job, generator())\n",
    "    P = np.zeros([n, n])\n",
    "    for i, thisP in result:\n",
    "        P[i, idx[i]] = thisP\n",
    "\n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w-yYkr_Xo5Ht"
   },
   "outputs": [],
   "source": [
    "def calculate_P(X):\n",
    "    n = X.shape[0]\n",
    "    P = np.zeros([n, batch_size])\n",
    "    for i in range(0, n, batch_size):\n",
    "        P_batch = x2p(X[i:i + batch_size])\n",
    "        P_batch[np.isnan(P_batch)] = 0\n",
    "        P_batch = P_batch + P_batch.T\n",
    "        P_batch = P_batch / P_batch.sum()\n",
    "        P_batch = np.maximum(P_batch, 1e-12)\n",
    "        P[i:i + batch_size] = P_batch\n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5n74kG8do4Rj"
   },
   "outputs": [],
   "source": [
    "def KLdivergence(P, Y):\n",
    "    low_dim = 2\n",
    "    alpha = low_dim - 1.\n",
    "    sum_Y = K.sum(K.square(Y), axis=1)\n",
    "    eps = K.variable(10e-15)\n",
    "    D = sum_Y + K.reshape(sum_Y, [-1, 1]) - 2 * K.dot(Y, K.transpose(Y))\n",
    "    Q = K.pow(1 + D / alpha, -(alpha + 1) / 2)\n",
    "    Q *= K.variable(1 - np.eye(batch_size))\n",
    "    Q /= K.sum(Q)\n",
    "    Q = K.maximum(Q, eps)\n",
    "    C = K.log(P) - K.log(Q)\n",
    "    C = K.sum(P * C)\n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eGufp78jgHnA"
   },
   "outputs": [],
   "source": [
    "def LoadData():\n",
    "  print (\"Loading cifar-10\")\n",
    "  (X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "  dataset = (X_train, y_train), (X_test, y_test)\n",
    "  return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I-j2uiu9ssfi"
   },
   "outputs": [],
   "source": [
    "def Reshape(dataset):\n",
    "  (X_train, y_train), (X_test, y_test) = dataset\n",
    "  n, channel, row, col = X_train.shape\n",
    "  X_train = X_train.reshape(-1, channel * row * col)\n",
    "  X_test = X_test.reshape(-1, channel * row * col)\n",
    "  \n",
    "  print (\"X_train.shape:\", X_train.shape)\n",
    "  print (\"X_test.shape:\", X_test.shape)\n",
    "\n",
    "  dataset = (X_train, y_train), (X_test, y_test), n\n",
    "  return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J3uwakE0kluc"
   },
   "outputs": [],
   "source": [
    "def Normalize(dataset):\n",
    "  (X_train, y_train), (X_test, y_test), n = dataset\n",
    "  print (\"Max in training data before scaling:\", str(np.max(X_train)))\n",
    "  \n",
    "  X_train = X_train.astype('float32')\n",
    "  X_test = X_test.astype('float32')\n",
    "  X_train /= 255\n",
    "  X_test /= 255\n",
    "  minimum = np.min(X_train)\n",
    "  maximum = np.max(y_train)\n",
    "  \n",
    "  print (\"Max in training data after scaling:\", str(np.max(X_train)))\n",
    "  \n",
    "  dataset = (X_train, y_train), (X_test, y_test), n\n",
    "  return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U5pjZeXeth7f"
   },
   "outputs": [],
   "source": [
    "def GenerateBatch(batch_size,nb_epoch):\n",
    "  for epoch in range(nb_epoch):\n",
    "    for i in range(0, n, batch_size):\n",
    "      yield(X_train[i:i+batch_size], calculate_P(X_train[i:i+batch_size]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QfEgjjQJxBUG"
   },
   "outputs": [],
   "source": [
    "# Plot the training and validation loss + accuracy\n",
    "def plot_training(history):\n",
    "    acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "    epochs = range(len(acc))\n",
    "\n",
    "    plt.plot(epochs, acc, 'r.')\n",
    "    plt.plot(epochs, val_acc, 'r')\n",
    "    plt.title('Training and validation accuracy')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    plt.savefig('acc_vs_epochs.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "AioWITpLhpVc",
    "outputId": "32243050-f480-4c8d-8a10-c8cf14ae63bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cifar-10\n",
      "X_train.shape: (50000, 3072)\n",
      "X_test.shape: (10000, 3072)\n",
      "Max in training data before scaling: 255\n",
      "Max in training data after scaling: 1.0\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test), n  = Normalize(Reshape(LoadData()))\n",
    "n = 10000\n",
    "X_train = X_train[0:n]\n",
    "y_train = y_train[0:n]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 377
    },
    "colab_type": "code",
    "id": "260yYvP0vHVj",
    "outputId": "9e320fdb-4466-4750-9b77-182474eb0259"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0812 01:09:23.206142 139712706385792 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0812 01:09:23.221236 139712706385792 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0812 01:09:23.223717 139712706385792 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0812 01:09:23.259864 139712706385792 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0812 01:09:23.293410 139712706385792 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1521: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0812 01:09:23.359299 139712706385792 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0812 01:09:23.587536 139712706385792 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "100/100 [==============================] - 25s 254ms/step - loss: 0.5073 - val_loss: nan\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 47s 468ms/step - loss: 0.4797 - val_loss: nan\n"
     ]
    }
   ],
   "source": [
    "perplexity = 30.0\n",
    "n_jobs = 5\n",
    "nb_epoch = 2\n",
    "batch_size = 100\n",
    "\n",
    "\n",
    "# build model\n",
    "model = Sequential()\n",
    "model.add(Dense(20, input_shape=(X_train.shape[1],),activation='relu'))\n",
    "model.add(Dense(40, activation='relu'))\n",
    "model.add(Dense(2))\n",
    "model.compile(loss=KLdivergence, optimizer=\"adam\")\n",
    "\n",
    "\n",
    "# fit model\n",
    "history = model.fit_generator(GenerateBatch(batch_size,nb_epoch),steps_per_epoch=math.ceil(n/batch_size),epochs=nb_epoch, shuffle = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hEsv-3TdVhMw"
   },
   "outputs": [],
   "source": [
    "\n",
    "# plot \n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "pred = model.predict(X_test[0:100])\n",
    "plt.scatter(pred[:, 0], pred[:, 1], marker='o', s=4, edgecolor='')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TKmm0gxMU1vH"
   },
   "outputs": [],
   "source": [
    "# plot \n",
    "acc = history.history['loss']\n",
    "epochs = range(len(acc))\n",
    "\n",
    "\n",
    "plt.plot(epochs, acc, 'r.')\n",
    "\n",
    "plt.title('Training and validation accuracy')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.savefig('acc_vs_epochs.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "DlQR41yaRZYm",
    "outputId": "2be5cd62-d9ac-46ea-994b-46b118eb8419"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.5072732537984848, 0.479733766913414], 'val_loss': [nan, nan]}"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "CIFAR10 t-sne",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
